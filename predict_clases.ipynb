{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e039646",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-04 14:04:00.583741: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-04 14:04:00.583778: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-04 14:04:01.708298: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-04 14:04:01.708411: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-04 14:04:01.708423: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, roc_auc_score,roc_curve,accuracy_score,make_scorer,auc\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fc85624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_classifier(model, X, y, parameters=None, scorer_metrics=None):\n",
    "\n",
    "    grid_obj = GridSearchCV(estimator=model, param_grid=parameters,\n",
    "                            scoring=make_scorer(scorer_metrics), cv=5)\n",
    "\n",
    "    grid_fit = grid_obj.fit(X, y)\n",
    "\n",
    "    model_estimator = grid_fit.best_estimator_\n",
    "\n",
    "    model_estimator.fit(X, y)\n",
    "    y_pred = model_estimator.predict(X)\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"\\nModel performance on training set\\n------------------------\")\n",
    "    print(\"Final accuracy score on the training data: {:.4f}\".format(\n",
    "        accuracy_score(y, y_pred)))\n",
    "    print(\"Final precision score on training data: {:.4f}\".format(\n",
    "        precision_score(y, y_pred)))\n",
    "    print(\"Final Recall score on training data: {:.4f}\".format(\n",
    "        recall_score(y, y_pred)))\n",
    "    print(\"Final ROC AUC score on training data: {:.4f}\".format(\n",
    "        roc_auc_score(y, y_pred)))\n",
    "    print(\"\\n\")\n",
    "    print(\"The best parameters are: {}\".format(model_estimator))\n",
    "\n",
    "    return model_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8d887a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаём функцию для построения графика ROC-AUC \n",
    "def roc_auc_plot(model, X, y, label=None):\n",
    "\n",
    "    y_score = model.predict_proba(X)[:, 1]\n",
    "\n",
    "    roc = roc_curve(y, y_score)\n",
    "\n",
    "    plt.plot(roc[0], roc[1], label=label)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.xlabel('FPR')\n",
    "    plt.ylabel('TPR')\n",
    "\n",
    "    roc_score = auc(roc[0], roc[1])\n",
    "    print('AUC score of %s is %.4f.' % (label, roc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5180029",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(y, pred):\n",
    "    roc_score = roc_auc_score(y, pred)\n",
    "\n",
    "    fpr, tpr, threshold = roc_curve(y, pred)\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    lw = 2\n",
    "    plt.title('ROC-AUC Curve, %2.1f%%' % (100*roc_score), fontsize=14)\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=lw)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.xlabel('False Positive Rate', fontsize=14)\n",
    "    plt.ylabel('True Positive Rate', fontsize=14)\n",
    "    plt.savefig(\"roc_auc_final.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b481435",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2018 = pd.read_csv('./samples/y2018.csv')\n",
    "df_2019 = pd.read_csv('./samples/y2019.csv')\n",
    "df_2020 = pd.read_csv('./samples/y2020.csv')\n",
    "df_2021 = pd.read_csv('./samples/y2021.csv')\n",
    "df_2022 = pd.read_csv('./samples/y2022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74a2ff7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system:index</th>\n",
       "      <th>m_10</th>\n",
       "      <th>m_11</th>\n",
       "      <th>m_4</th>\n",
       "      <th>m_5</th>\n",
       "      <th>m_6</th>\n",
       "      <th>m_7</th>\n",
       "      <th>m_8</th>\n",
       "      <th>m_9</th>\n",
       "      <th>name</th>\n",
       "      <th>state</th>\n",
       "      <th>year</th>\n",
       "      <th>.geo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2_0_0</td>\n",
       "      <td>0.771702</td>\n",
       "      <td>0.256970</td>\n",
       "      <td>0.589903</td>\n",
       "      <td>0.798264</td>\n",
       "      <td>0.826473</td>\n",
       "      <td>0.489460</td>\n",
       "      <td>0.842676</td>\n",
       "      <td>0.785188</td>\n",
       "      <td>161_2019</td>\n",
       "      <td>1</td>\n",
       "      <td>y2018</td>\n",
       "      <td>{\"geodesic\":false,\"type\":\"Point\",\"coordinates\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2_1_0</td>\n",
       "      <td>0.555886</td>\n",
       "      <td>0.095696</td>\n",
       "      <td>0.228813</td>\n",
       "      <td>0.646295</td>\n",
       "      <td>0.833649</td>\n",
       "      <td>0.734022</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.665546</td>\n",
       "      <td>43E_2019</td>\n",
       "      <td>1</td>\n",
       "      <td>y2018</td>\n",
       "      <td>{\"geodesic\":false,\"type\":\"Point\",\"coordinates\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2_2_0</td>\n",
       "      <td>0.184525</td>\n",
       "      <td>0.018129</td>\n",
       "      <td>0.263804</td>\n",
       "      <td>0.809224</td>\n",
       "      <td>0.830125</td>\n",
       "      <td>0.644455</td>\n",
       "      <td>0.776864</td>\n",
       "      <td>0.785586</td>\n",
       "      <td>313_2020</td>\n",
       "      <td>0</td>\n",
       "      <td>y2018</td>\n",
       "      <td>{\"geodesic\":false,\"type\":\"Point\",\"coordinates\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2_3_0</td>\n",
       "      <td>0.594700</td>\n",
       "      <td>0.369903</td>\n",
       "      <td>0.387250</td>\n",
       "      <td>0.841079</td>\n",
       "      <td>0.897446</td>\n",
       "      <td>0.865163</td>\n",
       "      <td>0.878579</td>\n",
       "      <td>0.802358</td>\n",
       "      <td>134_2019</td>\n",
       "      <td>1</td>\n",
       "      <td>y2018</td>\n",
       "      <td>{\"geodesic\":false,\"type\":\"Point\",\"coordinates\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2_4_0</td>\n",
       "      <td>0.612999</td>\n",
       "      <td>0.181587</td>\n",
       "      <td>0.400805</td>\n",
       "      <td>0.825996</td>\n",
       "      <td>0.845218</td>\n",
       "      <td>0.597657</td>\n",
       "      <td>0.876725</td>\n",
       "      <td>0.100219</td>\n",
       "      <td>77E_2019</td>\n",
       "      <td>1</td>\n",
       "      <td>y2018</td>\n",
       "      <td>{\"geodesic\":false,\"type\":\"Point\",\"coordinates\"...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  system:index      m_10      m_11       m_4       m_5       m_6       m_7  \\\n",
       "0        2_0_0  0.771702  0.256970  0.589903  0.798264  0.826473  0.489460   \n",
       "1        2_1_0  0.555886  0.095696  0.228813  0.646295  0.833649  0.734022   \n",
       "2        2_2_0  0.184525  0.018129  0.263804  0.809224  0.830125  0.644455   \n",
       "3        2_3_0  0.594700  0.369903  0.387250  0.841079  0.897446  0.865163   \n",
       "4        2_4_0  0.612999  0.181587  0.400805  0.825996  0.845218  0.597657   \n",
       "\n",
       "        m_8       m_9      name  state   year  \\\n",
       "0  0.842676  0.785188  161_2019      1  y2018   \n",
       "1  0.794393  0.665546  43E_2019      1  y2018   \n",
       "2  0.776864  0.785586  313_2020      0  y2018   \n",
       "3  0.878579  0.802358  134_2019      1  y2018   \n",
       "4  0.876725  0.100219  77E_2019      1  y2018   \n",
       "\n",
       "                                                .geo  \n",
       "0  {\"geodesic\":false,\"type\":\"Point\",\"coordinates\"...  \n",
       "1  {\"geodesic\":false,\"type\":\"Point\",\"coordinates\"...  \n",
       "2  {\"geodesic\":false,\"type\":\"Point\",\"coordinates\"...  \n",
       "3  {\"geodesic\":false,\"type\":\"Point\",\"coordinates\"...  \n",
       "4  {\"geodesic\":false,\"type\":\"Point\",\"coordinates\"...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a12f28bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_df(data):\n",
    "    df = data.copy()\n",
    "    del df['system:index']\n",
    "    del df['name']\n",
    "    del df['year']\n",
    "    del df['.geo']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3281ac4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df_2018, df_2019, df_2020,df_2021,df_2022]\n",
    "result_df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c7a2bd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50e_sh_2022    135\n",
       "33k_sh_2022    118\n",
       "26k_sh_2022    116\n",
       "25e_sh_2022     83\n",
       "4e_sh_2022      81\n",
       "              ... \n",
       "173_2020         1\n",
       "276_2020         1\n",
       "367_2020         1\n",
       "54k_2019         1\n",
       "10e_sh_2022      1\n",
       "Name: name, Length: 787, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7959be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m_10</th>\n",
       "      <th>m_11</th>\n",
       "      <th>m_4</th>\n",
       "      <th>m_5</th>\n",
       "      <th>m_6</th>\n",
       "      <th>m_7</th>\n",
       "      <th>m_8</th>\n",
       "      <th>m_9</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.993550</td>\n",
       "      <td>-4.289760</td>\n",
       "      <td>0.288312</td>\n",
       "      <td>0.577447</td>\n",
       "      <td>0.716622</td>\n",
       "      <td>0.412513</td>\n",
       "      <td>0.649406</td>\n",
       "      <td>0.567419</td>\n",
       "      <td>0.7302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.971050</td>\n",
       "      <td>20.875641</td>\n",
       "      <td>0.129722</td>\n",
       "      <td>0.253050</td>\n",
       "      <td>0.214007</td>\n",
       "      <td>4.501124</td>\n",
       "      <td>0.186255</td>\n",
       "      <td>0.278829</td>\n",
       "      <td>0.4439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>0.027547</td>\n",
       "      <td>0.014791</td>\n",
       "      <td>0.062605</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>0.109643</td>\n",
       "      <td>0.012163</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.213617</td>\n",
       "      <td>0.023413</td>\n",
       "      <td>0.224581</td>\n",
       "      <td>0.404069</td>\n",
       "      <td>0.639998</td>\n",
       "      <td>0.447294</td>\n",
       "      <td>0.512794</td>\n",
       "      <td>0.503917</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.534104</td>\n",
       "      <td>0.228649</td>\n",
       "      <td>0.291175</td>\n",
       "      <td>0.670420</td>\n",
       "      <td>0.813716</td>\n",
       "      <td>0.687461</td>\n",
       "      <td>0.701702</td>\n",
       "      <td>0.678640</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.635525</td>\n",
       "      <td>0.426083</td>\n",
       "      <td>0.377113</td>\n",
       "      <td>0.776165</td>\n",
       "      <td>0.861820</td>\n",
       "      <td>0.794964</td>\n",
       "      <td>0.801592</td>\n",
       "      <td>0.768782</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.897895</td>\n",
       "      <td>0.784954</td>\n",
       "      <td>0.746556</td>\n",
       "      <td>0.922326</td>\n",
       "      <td>0.918665</td>\n",
       "      <td>0.936101</td>\n",
       "      <td>0.915713</td>\n",
       "      <td>0.888346</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              m_10         m_11          m_4          m_5          m_6  \\\n",
       "count  5000.000000  5000.000000  5000.000000  5000.000000  5000.000000   \n",
       "mean     -0.993550    -4.289760     0.288312     0.577447     0.716622   \n",
       "std      11.971050    20.875641     0.129722     0.253050     0.214007   \n",
       "min    -100.000000  -100.000000     0.027547     0.014791     0.062605   \n",
       "25%       0.213617     0.023413     0.224581     0.404069     0.639998   \n",
       "50%       0.534104     0.228649     0.291175     0.670420     0.813716   \n",
       "75%       0.635525     0.426083     0.377113     0.776165     0.861820   \n",
       "max       0.897895     0.784954     0.746556     0.922326     0.918665   \n",
       "\n",
       "               m_7          m_8          m_9      state  \n",
       "count  5000.000000  5000.000000  5000.000000  5000.0000  \n",
       "mean      0.412513     0.649406     0.567419     0.7302  \n",
       "std       4.501124     0.186255     0.278829     0.4439  \n",
       "min    -100.000000     0.109643     0.012163     0.0000  \n",
       "25%       0.447294     0.512794     0.503917     0.0000  \n",
       "50%       0.687461     0.701702     0.678640     1.0000  \n",
       "75%       0.794964     0.801592     0.768782     1.0000  \n",
       "max       0.936101     0.915713     0.888346     1.0000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db16bf72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5000 entries, 0 to 999\n",
      "Data columns (total 13 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   system:index  5000 non-null   object \n",
      " 1   m_10          5000 non-null   float64\n",
      " 2   m_11          5000 non-null   float64\n",
      " 3   m_4           5000 non-null   float64\n",
      " 4   m_5           5000 non-null   float64\n",
      " 5   m_6           5000 non-null   float64\n",
      " 6   m_7           5000 non-null   float64\n",
      " 7   m_8           5000 non-null   float64\n",
      " 8   m_9           5000 non-null   float64\n",
      " 9   name          5000 non-null   object \n",
      " 10  state         5000 non-null   int64  \n",
      " 11  year          5000 non-null   object \n",
      " 12  .geo          5000 non-null   object \n",
      "dtypes: float64(8), int64(1), object(4)\n",
      "memory usage: 546.9+ KB\n"
     ]
    }
   ],
   "source": [
    "result_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "169a9075",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = result_df[result_df.m_10 != -100.0]\n",
    "result_df = result_df[result_df.m_11 != -100.0]\n",
    "result_df = result_df[result_df.m_7 != -100.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d754541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7085c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "m_10  m_9    0.824781\n",
       "m_5   m_9    0.808532\n",
       "m_10  m_5    0.804918\n",
       "m_6   m_9    0.803546\n",
       "m_4   m_9    0.792689\n",
       "m_5   m_6    0.777688\n",
       "      m_4    0.774859\n",
       "m_9   m_7    0.767234\n",
       "m_6   m_7    0.724965\n",
       "m_9   m_8    0.718982\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = result_df.corr()\n",
    "c = corr.abs().unstack()\n",
    "c[c == 1] = 0\n",
    "c = c.sort_values(ascending=False).drop_duplicates()\n",
    "tmp = c.head(10)\n",
    "tmp.sort_values(ascending=True)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4268fe58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3386\n",
       "0    1307\n",
       "Name: state, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проверка на баланс классов - классы не сбалансированы\n",
    "result_df[\"state\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6c1c61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c5b0a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3386, 13)\n",
      "(1307, 13)\n"
     ]
    }
   ],
   "source": [
    "used = result_df[result_df[\"state\"] == 0]\n",
    "unused = result_df[result_df[\"state\"] ==  1]\n",
    "print(unused.shape)\n",
    "print(used.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d50d44fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1307, 13)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "unused_downsample = resample(unused,\n",
    "             replace=True,\n",
    "             n_samples=len(used),\n",
    "             random_state=42)\n",
    "\n",
    "print(unused_downsample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f70e247",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_downsampled = pd.concat([unused_downsample, used])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83a063d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    1307\n",
      "0    1307\n",
      "Name: state, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data_downsampled[\"state\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78042357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сгруппируем данные по столбцу \"name\"\n",
    "grouped = data_downsampled.groupby('name')\n",
    "\n",
    "# Разделим имена на 80% для обучения, 10% для проверки и 10% для тестирования\n",
    "np.random.seed(0)\n",
    "names = list(grouped.groups.keys())\n",
    "train_names = np.random.choice(names, int(0.8*len(names)), replace=False)\n",
    "remaining_names = np.setdiff1d(names, train_names)\n",
    "val_names = np.random.choice(remaining_names, int(0.5*len(remaining_names)), replace=False)\n",
    "test_names = np.setdiff1d(remaining_names, val_names)\n",
    "\n",
    "# Разделим данные на три набора на основе имен\n",
    "train_df = pd.concat([grouped.get_group(name) for name in train_names]).reset_index(drop=True)\n",
    "val_df = pd.concat([grouped.get_group(name) for name in val_names]).reset_index(drop=True)\n",
    "test_df = pd.concat([grouped.get_group(name) for name in test_names]).reset_index(drop=True)\n",
    "\n",
    "# Разделим годы в каждой группе имен на три группы\n",
    "for name, group in grouped:\n",
    "    if name in train_names:\n",
    "        set_df = train_df[train_df['name'] == name]\n",
    "    elif name in val_names:\n",
    "        set_df = val_df[val_df['name'] == name]\n",
    "    else:\n",
    "        set_df = test_df[test_df['name'] == name]\n",
    "    \n",
    "    years = list(group['year'].unique())\n",
    "    np.random.seed(0)\n",
    "    train_years = np.random.choice(years, int(0.8*len(years)), replace=False)\n",
    "    remaining_years = np.setdiff1d(years, train_years)\n",
    "    val_years = np.random.choice(remaining_years, int(0.5*len(remaining_years)), replace=False)\n",
    "    test_years = np.setdiff1d(remaining_years, val_years)\n",
    "    \n",
    "    set_df.loc[set_df['year'].isin(train_years), 'split'] = 'train'\n",
    "    set_df.loc[set_df['year'].isin(val_years), 'split'] = 'val'\n",
    "    set_df.loc[set_df['year'].isin(test_years), 'split'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "527c8c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1961\n",
      "330\n",
      "323\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df))\n",
    "print(len(val_df))\n",
    "print(len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4a8f724",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=prepare_df(train_df)\n",
    "val_df=prepare_df(val_df)\n",
    "test_df=prepare_df(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d1aaa3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# разделяем искомую переменную от всех данных\n",
    "X_train = train_df.drop(columns=['state'])\n",
    "y_train = train_df['state']\n",
    "X_test = test_df.drop(columns=['state'])\n",
    "y_test = test_df['state']\n",
    "X_val = val_df.drop(columns=['state'])\n",
    "y_val = val_df['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c18c8c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1961, 8)\n",
      "(323, 8)\n",
      "(330, 8)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8476ee4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m_10</th>\n",
       "      <th>m_11</th>\n",
       "      <th>m_4</th>\n",
       "      <th>m_5</th>\n",
       "      <th>m_6</th>\n",
       "      <th>m_7</th>\n",
       "      <th>m_8</th>\n",
       "      <th>m_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.669041</td>\n",
       "      <td>0.158649</td>\n",
       "      <td>0.289833</td>\n",
       "      <td>0.619844</td>\n",
       "      <td>0.661807</td>\n",
       "      <td>0.486317</td>\n",
       "      <td>0.721060</td>\n",
       "      <td>0.707134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.671044</td>\n",
       "      <td>0.208358</td>\n",
       "      <td>0.344216</td>\n",
       "      <td>0.586012</td>\n",
       "      <td>0.565657</td>\n",
       "      <td>0.458737</td>\n",
       "      <td>0.696694</td>\n",
       "      <td>0.678773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.671044</td>\n",
       "      <td>0.208358</td>\n",
       "      <td>0.344216</td>\n",
       "      <td>0.586012</td>\n",
       "      <td>0.565657</td>\n",
       "      <td>0.458737</td>\n",
       "      <td>0.696694</td>\n",
       "      <td>0.678773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.564226</td>\n",
       "      <td>0.324536</td>\n",
       "      <td>0.445970</td>\n",
       "      <td>0.785858</td>\n",
       "      <td>0.890573</td>\n",
       "      <td>0.752947</td>\n",
       "      <td>0.442255</td>\n",
       "      <td>0.734556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.244644</td>\n",
       "      <td>0.130102</td>\n",
       "      <td>0.243329</td>\n",
       "      <td>0.207050</td>\n",
       "      <td>0.544581</td>\n",
       "      <td>0.863509</td>\n",
       "      <td>0.804263</td>\n",
       "      <td>0.843711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       m_10      m_11       m_4       m_5       m_6       m_7       m_8  \\\n",
       "0  0.669041  0.158649  0.289833  0.619844  0.661807  0.486317  0.721060   \n",
       "1  0.671044  0.208358  0.344216  0.586012  0.565657  0.458737  0.696694   \n",
       "2  0.671044  0.208358  0.344216  0.586012  0.565657  0.458737  0.696694   \n",
       "3  0.564226  0.324536  0.445970  0.785858  0.890573  0.752947  0.442255   \n",
       "4  0.244644  0.130102  0.243329  0.207050  0.544581  0.863509  0.804263   \n",
       "\n",
       "        m_9  \n",
       "0  0.707134  \n",
       "1  0.678773  \n",
       "2  0.678773  \n",
       "3  0.734556  \n",
       "4  0.843711  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7190edfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Model performance on training set\n",
      "------------------------\n",
      "Final accuracy score on the training data: 0.7991\n",
      "Final precision score on training data: 0.8236\n",
      "Final Recall score on training data: 0.7671\n",
      "Final ROC AUC score on training data: 0.7995\n",
      "\n",
      "\n",
      "The best parameters are: DecisionTreeClassifier(max_depth=5, min_samples_leaf=2, random_state=44)\n"
     ]
    }
   ],
   "source": [
    "# найдем и построим наилучшую модельмодель для DecisionTree\n",
    "parameters_DT = {'max_depth': [3, 5, 7],\n",
    "                 'min_samples_leaf': [2, 3, 4],\n",
    "                 'min_samples_split': [2, 3, 4]}\n",
    "\n",
    "model_DT = fit_classifier(DecisionTreeClassifier(random_state=44), X_train, y_train,\n",
    "                          parameters=parameters_DT, scorer_metrics=recall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74c6cd58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Model performance on training set\n",
      "------------------------\n",
      "Final accuracy score on the training data: 0.7568\n",
      "Final precision score on training data: 0.7137\n",
      "Final Recall score on training data: 0.8669\n",
      "Final ROC AUC score on training data: 0.7554\n",
      "\n",
      "\n",
      "The best parameters are: RandomForestClassifier(max_depth=2, min_samples_leaf=2, n_estimators=10,\n",
      "                       random_state=18)\n"
     ]
    }
   ],
   "source": [
    "# найдем и построим наилучшую модель для random forest\n",
    "# Create the parameters list\n",
    "parameters_RF = {'n_estimators':[10,50],'max_depth': [2, 5, 7,10], 'min_samples_leaf': [\n",
    "    2, 3, 5, 7, 10], 'min_samples_split': [2, 3, 5]}\n",
    "\n",
    "model_RF = fit_classifier(RandomForestClassifier(random_state=18), X_train, y_train,\n",
    "                          parameters=parameters_RF, scorer_metrics=recall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cbc63d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score of Random Forest is 0.7698.\n",
      "AUC score of Decision Tree is 0.8131.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "roc_auc_plot(model_RF, X_test, y_test, label='Random Forest')\n",
    "roc_auc_plot(model_DT, X_test, y_test, label='Decision Tree')\n",
    "plt.title('ROC Curves on Valid Set')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig(\"roc_valid.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "821fb234",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_confusion_matrix(X, y, model, threshold=0.5):\n",
    "    pred = model.predict_proba(X)[:, 1]\n",
    "    pred = [1 if p >= threshold else 0 for p in pred]\n",
    "    cm = pd.DataFrame(confusion_matrix(y, pred),\n",
    "                      index=[\"actual 0\", \"actual 1\"], columns=[\"pred 0\", \"pred 1\"])\n",
    "    print(\"Threshold = %.2f\" % threshold)\n",
    "    print(\"Accuracy score: %.1f%%\" % (100 * accuracy_score(y, pred)))\n",
    "    print(\"Confusion matrix:\")\n",
    "    display(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f4877c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold = 0.60\n",
      "Accuracy score: 65.3%\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred 0</th>\n",
       "      <th>pred 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual 0</th>\n",
       "      <td>92</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual 1</th>\n",
       "      <td>91</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pred 0  pred 1\n",
       "actual 0      92      21\n",
       "actual 1      91     119"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_confusion_matrix(X_test, y_test, model_DT, threshold=.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "329aa08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold = 0.60\n",
      "Accuracy score: 61.6%\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred 0</th>\n",
       "      <th>pred 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual 0</th>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual 1</th>\n",
       "      <td>123</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pred 0  pred 1\n",
       "actual 0     112       1\n",
       "actual 1     123      87"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_confusion_matrix(X_test, y_test, model_RF, threshold=.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cabcd4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 76.1%\n"
     ]
    }
   ],
   "source": [
    "pred = model_DT.predict(X_val)\n",
    "print(\"Accuracy score: %.1f%%\" % (100 * accuracy_score(y_val, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ebf86717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 80.9%\n"
     ]
    }
   ],
   "source": [
    "pred = model_RF.predict(X_val)\n",
    "print(\"Accuracy score: %.1f%%\" % (100 * accuracy_score(y_val, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d65e24d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "321df947",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)\n",
    "y_val=tf.keras.utils.to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "182cc5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-04 14:05:07.356652: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-04 14:05:07.356691: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-04 14:05:07.356734: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (vladimir-ProBook): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu', input_shape=(8,)))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ad992ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0b49c206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1961, 8)\n",
      "(323, 8)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43cc581",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c5a6af67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "62/62 [==============================] - 1s 7ms/step - loss: 0.7036 - accuracy: 0.5110 - val_loss: 0.6728 - val_accuracy: 0.6502\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.4957 - val_loss: 0.6755 - val_accuracy: 0.6502\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6895 - accuracy: 0.5171 - val_loss: 0.6639 - val_accuracy: 0.6502\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6855 - accuracy: 0.5365 - val_loss: 0.6679 - val_accuracy: 0.7214\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6801 - accuracy: 0.5604 - val_loss: 0.6600 - val_accuracy: 0.6563\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6820 - accuracy: 0.5507 - val_loss: 0.6609 - val_accuracy: 0.7368\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6710 - accuracy: 0.6191 - val_loss: 0.6439 - val_accuracy: 0.7307\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6693 - accuracy: 0.5941 - val_loss: 0.6452 - val_accuracy: 0.6594\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6544 - accuracy: 0.6293 - val_loss: 0.6218 - val_accuracy: 0.6842\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6446 - accuracy: 0.6369 - val_loss: 0.6488 - val_accuracy: 0.5913\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6444 - accuracy: 0.6344 - val_loss: 0.6064 - val_accuracy: 0.6904\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6309 - accuracy: 0.6537 - val_loss: 0.6252 - val_accuracy: 0.6378\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6236 - accuracy: 0.6665 - val_loss: 0.5756 - val_accuracy: 0.7307\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6252 - accuracy: 0.6690 - val_loss: 0.5823 - val_accuracy: 0.7059\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6082 - accuracy: 0.6849 - val_loss: 0.5895 - val_accuracy: 0.7090\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6085 - accuracy: 0.6736 - val_loss: 0.5641 - val_accuracy: 0.7214\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5965 - accuracy: 0.6833 - val_loss: 0.5699 - val_accuracy: 0.7214\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6019 - accuracy: 0.6915 - val_loss: 0.5923 - val_accuracy: 0.6997\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5957 - accuracy: 0.7068 - val_loss: 0.5916 - val_accuracy: 0.6935\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5855 - accuracy: 0.7088 - val_loss: 0.6125 - val_accuracy: 0.6687\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5767 - accuracy: 0.7114 - val_loss: 0.5602 - val_accuracy: 0.7121\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5635 - accuracy: 0.7246 - val_loss: 0.5666 - val_accuracy: 0.7121\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5787 - accuracy: 0.7124 - val_loss: 0.5678 - val_accuracy: 0.7090\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5650 - accuracy: 0.7292 - val_loss: 0.5466 - val_accuracy: 0.7152\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5640 - accuracy: 0.7302 - val_loss: 0.5684 - val_accuracy: 0.7059\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5547 - accuracy: 0.7404 - val_loss: 0.5758 - val_accuracy: 0.7028\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5502 - accuracy: 0.7333 - val_loss: 0.5633 - val_accuracy: 0.7183\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5514 - accuracy: 0.7297 - val_loss: 0.5443 - val_accuracy: 0.7245\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5314 - accuracy: 0.7476 - val_loss: 0.5560 - val_accuracy: 0.6873\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5438 - accuracy: 0.7420 - val_loss: 0.5800 - val_accuracy: 0.6904\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5482 - accuracy: 0.7374 - val_loss: 0.5758 - val_accuracy: 0.6904\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5442 - accuracy: 0.7557 - val_loss: 0.5558 - val_accuracy: 0.6780\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5261 - accuracy: 0.7471 - val_loss: 0.5896 - val_accuracy: 0.6811\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5121 - accuracy: 0.7578 - val_loss: 0.5513 - val_accuracy: 0.6997\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5188 - accuracy: 0.7511 - val_loss: 0.5539 - val_accuracy: 0.6904\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5210 - accuracy: 0.7583 - val_loss: 0.5483 - val_accuracy: 0.6811\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5146 - accuracy: 0.7685 - val_loss: 0.5470 - val_accuracy: 0.6780\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5188 - accuracy: 0.7624 - val_loss: 0.5382 - val_accuracy: 0.7059\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5205 - accuracy: 0.7603 - val_loss: 0.5373 - val_accuracy: 0.6842\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5028 - accuracy: 0.7695 - val_loss: 0.5753 - val_accuracy: 0.6594\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4980 - accuracy: 0.7700 - val_loss: 0.5540 - val_accuracy: 0.6997\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5107 - accuracy: 0.7715 - val_loss: 0.5452 - val_accuracy: 0.6935\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5030 - accuracy: 0.7700 - val_loss: 0.5590 - val_accuracy: 0.6842\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5127 - accuracy: 0.7613 - val_loss: 0.5381 - val_accuracy: 0.6966\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4899 - accuracy: 0.7736 - val_loss: 0.5515 - val_accuracy: 0.6749\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4775 - accuracy: 0.7812 - val_loss: 0.5335 - val_accuracy: 0.6966\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4885 - accuracy: 0.7874 - val_loss: 0.5240 - val_accuracy: 0.7183\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4829 - accuracy: 0.7817 - val_loss: 0.5597 - val_accuracy: 0.6873\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4988 - accuracy: 0.7659 - val_loss: 0.5499 - val_accuracy: 0.6811\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4991 - accuracy: 0.7664 - val_loss: 0.5463 - val_accuracy: 0.6904\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4794 - accuracy: 0.7690 - val_loss: 0.5286 - val_accuracy: 0.6687\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4713 - accuracy: 0.7843 - val_loss: 0.5493 - val_accuracy: 0.6749\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4900 - accuracy: 0.7710 - val_loss: 0.5520 - val_accuracy: 0.6780\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4820 - accuracy: 0.7879 - val_loss: 0.5305 - val_accuracy: 0.6966\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4892 - accuracy: 0.7838 - val_loss: 0.5261 - val_accuracy: 0.6873\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4764 - accuracy: 0.7833 - val_loss: 0.5446 - val_accuracy: 0.6873\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4735 - accuracy: 0.7930 - val_loss: 0.5117 - val_accuracy: 0.7028\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4726 - accuracy: 0.7802 - val_loss: 0.5159 - val_accuracy: 0.7121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4628 - accuracy: 0.7838 - val_loss: 0.5551 - val_accuracy: 0.6533\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4818 - accuracy: 0.7838 - val_loss: 0.5635 - val_accuracy: 0.6687\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4702 - accuracy: 0.7914 - val_loss: 0.5442 - val_accuracy: 0.6533\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4601 - accuracy: 0.7838 - val_loss: 0.5378 - val_accuracy: 0.6935\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4791 - accuracy: 0.7761 - val_loss: 0.5410 - val_accuracy: 0.6811\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4770 - accuracy: 0.7848 - val_loss: 0.5089 - val_accuracy: 0.7028\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.7884 - val_loss: 0.5193 - val_accuracy: 0.7214\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4696 - accuracy: 0.7884 - val_loss: 0.5603 - val_accuracy: 0.6563\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4759 - accuracy: 0.7833 - val_loss: 0.5408 - val_accuracy: 0.6533\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4736 - accuracy: 0.7858 - val_loss: 0.5313 - val_accuracy: 0.7121\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.7960 - val_loss: 0.5195 - val_accuracy: 0.6966\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4654 - accuracy: 0.7940 - val_loss: 0.5007 - val_accuracy: 0.7276\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4558 - accuracy: 0.7960 - val_loss: 0.5126 - val_accuracy: 0.6997\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.7955 - val_loss: 0.5569 - val_accuracy: 0.6780\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4572 - accuracy: 0.7919 - val_loss: 0.5074 - val_accuracy: 0.7090\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4643 - accuracy: 0.7899 - val_loss: 0.5520 - val_accuracy: 0.6533\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4792 - accuracy: 0.7823 - val_loss: 0.5337 - val_accuracy: 0.6904\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.7868 - val_loss: 0.5539 - val_accuracy: 0.6718\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4698 - accuracy: 0.7868 - val_loss: 0.5245 - val_accuracy: 0.6811\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4554 - accuracy: 0.7930 - val_loss: 0.5789 - val_accuracy: 0.6687\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4791 - accuracy: 0.7863 - val_loss: 0.5379 - val_accuracy: 0.6749\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4480 - accuracy: 0.8032 - val_loss: 0.5370 - val_accuracy: 0.6997\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4485 - accuracy: 0.7986 - val_loss: 0.5180 - val_accuracy: 0.7090\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4497 - accuracy: 0.7950 - val_loss: 0.5267 - val_accuracy: 0.7121\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4523 - accuracy: 0.7909 - val_loss: 0.5553 - val_accuracy: 0.6966\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.7756 - val_loss: 0.5268 - val_accuracy: 0.6935\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4554 - accuracy: 0.7874 - val_loss: 0.5457 - val_accuracy: 0.6904\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4477 - accuracy: 0.8047 - val_loss: 0.5444 - val_accuracy: 0.6997\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4549 - accuracy: 0.8011 - val_loss: 0.5255 - val_accuracy: 0.7028\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4481 - accuracy: 0.8001 - val_loss: 0.5137 - val_accuracy: 0.7245\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4445 - accuracy: 0.7981 - val_loss: 0.5005 - val_accuracy: 0.7183\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4632 - accuracy: 0.8011 - val_loss: 0.5293 - val_accuracy: 0.6997\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4629 - accuracy: 0.7817 - val_loss: 0.5365 - val_accuracy: 0.6594\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.7853 - val_loss: 0.5150 - val_accuracy: 0.6966\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4473 - accuracy: 0.7965 - val_loss: 0.5238 - val_accuracy: 0.7152\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4454 - accuracy: 0.8047 - val_loss: 0.5240 - val_accuracy: 0.6966\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4526 - accuracy: 0.8032 - val_loss: 0.5225 - val_accuracy: 0.6873\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4413 - accuracy: 0.8062 - val_loss: 0.5270 - val_accuracy: 0.6935\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7899 - val_loss: 0.5599 - val_accuracy: 0.6687\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4536 - accuracy: 0.7853 - val_loss: 0.5400 - val_accuracy: 0.6935\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4433 - accuracy: 0.8037 - val_loss: 0.5615 - val_accuracy: 0.6904\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4476 - accuracy: 0.7991 - val_loss: 0.5478 - val_accuracy: 0.6873\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "adada34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.7364\n",
      "Test Accuracy: 73.64%\n"
     ]
    }
   ],
   "source": [
    "#y_valid = tf.keras.utils.to_categorical(y_val)\n",
    "test_loss, test_acc = model.evaluate(X_val, y_val)\n",
    "print('Test Accuracy: {:.2f}%'.format(test_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d30914b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = tf.keras.Sequential()\n",
    "model1.add(tf.keras.layers.Dense(64, activation='relu', input_shape=(8,)))\n",
    "model1.add(tf.keras.layers.Dropout(0.5))\n",
    "model1.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model1.add(tf.keras.layers.Dropout(0.5))\n",
    "model1.add(tf.keras.layers.Dense(16, activation='softmax'))\n",
    "model1.add(tf.keras.layers.Dropout(0.5))\n",
    "model1.add(tf.keras.layers.Dense(2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "88b8e95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9cdc94a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "62/62 [==============================] - 1s 6ms/step - loss: 0.6944 - accuracy: 0.5166 - val_loss: 0.6865 - val_accuracy: 0.6502\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6943 - accuracy: 0.4941 - val_loss: 0.6838 - val_accuracy: 0.6502\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5120 - val_loss: 0.6820 - val_accuracy: 0.6502\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6897 - accuracy: 0.5385 - val_loss: 0.6806 - val_accuracy: 0.6099\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6869 - accuracy: 0.5472 - val_loss: 0.6787 - val_accuracy: 0.5975\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6895 - accuracy: 0.5426 - val_loss: 0.6850 - val_accuracy: 0.5975\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6815 - accuracy: 0.5783 - val_loss: 0.6756 - val_accuracy: 0.5882\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6802 - accuracy: 0.5594 - val_loss: 0.6732 - val_accuracy: 0.5882\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6793 - accuracy: 0.5727 - val_loss: 0.6720 - val_accuracy: 0.6718\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6753 - accuracy: 0.5742 - val_loss: 0.6668 - val_accuracy: 0.6687\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6654 - accuracy: 0.6150 - val_loss: 0.6637 - val_accuracy: 0.6440\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6576 - accuracy: 0.6099 - val_loss: 0.6538 - val_accuracy: 0.6440\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6468 - accuracy: 0.6328 - val_loss: 0.6331 - val_accuracy: 0.6966\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6456 - accuracy: 0.6364 - val_loss: 0.6317 - val_accuracy: 0.6749\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6367 - accuracy: 0.6532 - val_loss: 0.6271 - val_accuracy: 0.6904\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6367 - accuracy: 0.6543 - val_loss: 0.6165 - val_accuracy: 0.7028\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6322 - accuracy: 0.6685 - val_loss: 0.6069 - val_accuracy: 0.7152\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6230 - accuracy: 0.6588 - val_loss: 0.6098 - val_accuracy: 0.7090\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6224 - accuracy: 0.6818 - val_loss: 0.5981 - val_accuracy: 0.7245\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6152 - accuracy: 0.6639 - val_loss: 0.6164 - val_accuracy: 0.6966\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6181 - accuracy: 0.6798 - val_loss: 0.5899 - val_accuracy: 0.7214\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6122 - accuracy: 0.6823 - val_loss: 0.6087 - val_accuracy: 0.7059\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6137 - accuracy: 0.6900 - val_loss: 0.5809 - val_accuracy: 0.7368\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6106 - accuracy: 0.6741 - val_loss: 0.5884 - val_accuracy: 0.7245\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6096 - accuracy: 0.6803 - val_loss: 0.6156 - val_accuracy: 0.6904\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6083 - accuracy: 0.6925 - val_loss: 0.5977 - val_accuracy: 0.7121\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6066 - accuracy: 0.6874 - val_loss: 0.5864 - val_accuracy: 0.7183\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6055 - accuracy: 0.7002 - val_loss: 0.5931 - val_accuracy: 0.7152\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5939 - accuracy: 0.7088 - val_loss: 0.5986 - val_accuracy: 0.7028\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5978 - accuracy: 0.7058 - val_loss: 0.5752 - val_accuracy: 0.7307\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5916 - accuracy: 0.7007 - val_loss: 0.5885 - val_accuracy: 0.7183\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6038 - accuracy: 0.7098 - val_loss: 0.5845 - val_accuracy: 0.7121\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5915 - accuracy: 0.7134 - val_loss: 0.5858 - val_accuracy: 0.7090\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5905 - accuracy: 0.7068 - val_loss: 0.5674 - val_accuracy: 0.7307\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5963 - accuracy: 0.7068 - val_loss: 0.5933 - val_accuracy: 0.7090\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5833 - accuracy: 0.7144 - val_loss: 0.5744 - val_accuracy: 0.7090\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5744 - accuracy: 0.7297 - val_loss: 0.5785 - val_accuracy: 0.7121\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5826 - accuracy: 0.7180 - val_loss: 0.5762 - val_accuracy: 0.7059\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5820 - accuracy: 0.7165 - val_loss: 0.5823 - val_accuracy: 0.7090\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5848 - accuracy: 0.7160 - val_loss: 0.5569 - val_accuracy: 0.7307\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5785 - accuracy: 0.7313 - val_loss: 0.5768 - val_accuracy: 0.7090\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5763 - accuracy: 0.7262 - val_loss: 0.6056 - val_accuracy: 0.7059\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5883 - accuracy: 0.7175 - val_loss: 0.5799 - val_accuracy: 0.7152\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5669 - accuracy: 0.7374 - val_loss: 0.6008 - val_accuracy: 0.7121\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5669 - accuracy: 0.7328 - val_loss: 0.5673 - val_accuracy: 0.6966\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5680 - accuracy: 0.7399 - val_loss: 0.5729 - val_accuracy: 0.7121\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5599 - accuracy: 0.7415 - val_loss: 0.5637 - val_accuracy: 0.7059\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5582 - accuracy: 0.7471 - val_loss: 0.5751 - val_accuracy: 0.7028\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5620 - accuracy: 0.7287 - val_loss: 0.5699 - val_accuracy: 0.6997\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5536 - accuracy: 0.7420 - val_loss: 0.5790 - val_accuracy: 0.7090\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5548 - accuracy: 0.7440 - val_loss: 0.5815 - val_accuracy: 0.7090\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5545 - accuracy: 0.7481 - val_loss: 0.5976 - val_accuracy: 0.7028\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5469 - accuracy: 0.7394 - val_loss: 0.5833 - val_accuracy: 0.7214\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5447 - accuracy: 0.7511 - val_loss: 0.5717 - val_accuracy: 0.7276\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5497 - accuracy: 0.7440 - val_loss: 0.5644 - val_accuracy: 0.7028\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5490 - accuracy: 0.7532 - val_loss: 0.5642 - val_accuracy: 0.7183\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5570 - accuracy: 0.7358 - val_loss: 0.5598 - val_accuracy: 0.6935\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5345 - accuracy: 0.7460 - val_loss: 0.5568 - val_accuracy: 0.6873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5438 - accuracy: 0.7517 - val_loss: 0.5782 - val_accuracy: 0.7059\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5376 - accuracy: 0.7629 - val_loss: 0.5621 - val_accuracy: 0.6935\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5332 - accuracy: 0.7624 - val_loss: 0.5727 - val_accuracy: 0.6997\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5361 - accuracy: 0.7440 - val_loss: 0.5848 - val_accuracy: 0.6811\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5450 - accuracy: 0.7481 - val_loss: 0.5557 - val_accuracy: 0.6935\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5310 - accuracy: 0.7552 - val_loss: 0.5713 - val_accuracy: 0.6935\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5405 - accuracy: 0.7598 - val_loss: 0.5837 - val_accuracy: 0.6966\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5236 - accuracy: 0.7624 - val_loss: 0.5616 - val_accuracy: 0.7090\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5408 - accuracy: 0.7506 - val_loss: 0.5741 - val_accuracy: 0.6997\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5230 - accuracy: 0.7644 - val_loss: 0.5925 - val_accuracy: 0.6935\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5282 - accuracy: 0.7629 - val_loss: 0.5510 - val_accuracy: 0.7090\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5309 - accuracy: 0.7603 - val_loss: 0.5628 - val_accuracy: 0.7059\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5247 - accuracy: 0.7613 - val_loss: 0.5591 - val_accuracy: 0.6935\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.7884 - val_loss: 0.5579 - val_accuracy: 0.6873\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.7797 - val_loss: 0.5857 - val_accuracy: 0.6904\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5240 - accuracy: 0.7664 - val_loss: 0.5806 - val_accuracy: 0.6997\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5169 - accuracy: 0.7721 - val_loss: 0.5471 - val_accuracy: 0.7028\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5138 - accuracy: 0.7766 - val_loss: 0.5661 - val_accuracy: 0.7090\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5188 - accuracy: 0.7634 - val_loss: 0.5695 - val_accuracy: 0.6935\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7817 - val_loss: 0.5585 - val_accuracy: 0.6842\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5030 - accuracy: 0.7766 - val_loss: 0.5716 - val_accuracy: 0.6904\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7680 - val_loss: 0.5683 - val_accuracy: 0.6811\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5118 - accuracy: 0.7710 - val_loss: 0.5605 - val_accuracy: 0.6966\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.7746 - val_loss: 0.5445 - val_accuracy: 0.6997\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5198 - accuracy: 0.7695 - val_loss: 0.5667 - val_accuracy: 0.6904\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4973 - accuracy: 0.7828 - val_loss: 0.5634 - val_accuracy: 0.6997\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5015 - accuracy: 0.7848 - val_loss: 0.5688 - val_accuracy: 0.6966\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5128 - accuracy: 0.7741 - val_loss: 0.5473 - val_accuracy: 0.7152\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.7843 - val_loss: 0.5876 - val_accuracy: 0.6842\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7833 - val_loss: 0.5708 - val_accuracy: 0.6997\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4995 - accuracy: 0.7792 - val_loss: 0.5450 - val_accuracy: 0.6966\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4927 - accuracy: 0.7828 - val_loss: 0.5326 - val_accuracy: 0.7337\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4966 - accuracy: 0.7817 - val_loss: 0.5661 - val_accuracy: 0.6997\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5016 - accuracy: 0.7797 - val_loss: 0.5569 - val_accuracy: 0.7090\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4997 - accuracy: 0.7838 - val_loss: 0.5831 - val_accuracy: 0.6935\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7823 - val_loss: 0.5650 - val_accuracy: 0.6935\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5013 - accuracy: 0.7823 - val_loss: 0.5866 - val_accuracy: 0.6904\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5084 - accuracy: 0.7654 - val_loss: 0.5646 - val_accuracy: 0.6997\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4961 - accuracy: 0.7919 - val_loss: 0.5729 - val_accuracy: 0.6873\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4871 - accuracy: 0.7802 - val_loss: 0.5526 - val_accuracy: 0.7028\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4909 - accuracy: 0.7741 - val_loss: 0.5255 - val_accuracy: 0.7307\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4890 - accuracy: 0.7802 - val_loss: 0.5497 - val_accuracy: 0.7028\n"
     ]
    }
   ],
   "source": [
    "history = model1.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "34190644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5224 - accuracy: 0.7606\n",
      "Test Accuracy: 76.06%\n"
     ]
    }
   ],
   "source": [
    "#y_valid = tf.keras.utils.to_categorical(y_val)\n",
    "test_loss, test_acc = model1.evaluate(X_val, y_val)\n",
    "print('Test Accuracy: {:.2f}%'.format(test_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ddc0f80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = tf.keras.Sequential()\n",
    "model2.add(tf.keras.layers.Dense(64, activation='relu', input_shape=(8,)))\n",
    "model2.add(tf.keras.layers.Dropout(0.5))\n",
    "model2.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model2.add(tf.keras.layers.Dropout(0.5))\n",
    "model2.add(tf.keras.layers.Dense(8, activation='softmax'))\n",
    "model2.add(tf.keras.layers.Dropout(0.5))\n",
    "model2.add(tf.keras.layers.Dense(2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ef058df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9088a6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "62/62 [==============================] - 1s 6ms/step - loss: 0.7058 - accuracy: 0.5043 - val_loss: 0.7031 - val_accuracy: 0.3498\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6976 - accuracy: 0.5171 - val_loss: 0.6835 - val_accuracy: 0.5882\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.6948 - accuracy: 0.5125 - val_loss: 0.6808 - val_accuracy: 0.5882\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6920 - accuracy: 0.5263 - val_loss: 0.6768 - val_accuracy: 0.5975\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6904 - accuracy: 0.5385 - val_loss: 0.6779 - val_accuracy: 0.5882\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6853 - accuracy: 0.5487 - val_loss: 0.6759 - val_accuracy: 0.5882\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6815 - accuracy: 0.5665 - val_loss: 0.6706 - val_accuracy: 0.5975\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6802 - accuracy: 0.5635 - val_loss: 0.6768 - val_accuracy: 0.6842\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6785 - accuracy: 0.5757 - val_loss: 0.6697 - val_accuracy: 0.6904\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6684 - accuracy: 0.6022 - val_loss: 0.6549 - val_accuracy: 0.7121\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6665 - accuracy: 0.5951 - val_loss: 0.6520 - val_accuracy: 0.6842\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6554 - accuracy: 0.6272 - val_loss: 0.6494 - val_accuracy: 0.6842\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6494 - accuracy: 0.6242 - val_loss: 0.6235 - val_accuracy: 0.7245\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6445 - accuracy: 0.6486 - val_loss: 0.6301 - val_accuracy: 0.6935\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6276 - accuracy: 0.6639 - val_loss: 0.6179 - val_accuracy: 0.6873\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6222 - accuracy: 0.6711 - val_loss: 0.6166 - val_accuracy: 0.6966\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6301 - accuracy: 0.6435 - val_loss: 0.5983 - val_accuracy: 0.7059\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6148 - accuracy: 0.6838 - val_loss: 0.6175 - val_accuracy: 0.6842\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6155 - accuracy: 0.6741 - val_loss: 0.5846 - val_accuracy: 0.7183\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6173 - accuracy: 0.6731 - val_loss: 0.5955 - val_accuracy: 0.7090\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6085 - accuracy: 0.6864 - val_loss: 0.5989 - val_accuracy: 0.7121\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6000 - accuracy: 0.7027 - val_loss: 0.5736 - val_accuracy: 0.7183\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6008 - accuracy: 0.6889 - val_loss: 0.5835 - val_accuracy: 0.7245\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5913 - accuracy: 0.7155 - val_loss: 0.5849 - val_accuracy: 0.7183\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5928 - accuracy: 0.7047 - val_loss: 0.5686 - val_accuracy: 0.7183\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5840 - accuracy: 0.7073 - val_loss: 0.5673 - val_accuracy: 0.7183\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5845 - accuracy: 0.7124 - val_loss: 0.5717 - val_accuracy: 0.7245\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5831 - accuracy: 0.7231 - val_loss: 0.5837 - val_accuracy: 0.7121\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5818 - accuracy: 0.7211 - val_loss: 0.5577 - val_accuracy: 0.7121\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5672 - accuracy: 0.7307 - val_loss: 0.5511 - val_accuracy: 0.7183\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5771 - accuracy: 0.7241 - val_loss: 0.5440 - val_accuracy: 0.7245\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5658 - accuracy: 0.7292 - val_loss: 0.5612 - val_accuracy: 0.6966\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5744 - accuracy: 0.7211 - val_loss: 0.5671 - val_accuracy: 0.6997\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5650 - accuracy: 0.7231 - val_loss: 0.5640 - val_accuracy: 0.6935\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5668 - accuracy: 0.7190 - val_loss: 0.5362 - val_accuracy: 0.7276\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5611 - accuracy: 0.7409 - val_loss: 0.5487 - val_accuracy: 0.7368\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5707 - accuracy: 0.7287 - val_loss: 0.5640 - val_accuracy: 0.7090\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5545 - accuracy: 0.7445 - val_loss: 0.5718 - val_accuracy: 0.6966\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5580 - accuracy: 0.7333 - val_loss: 0.5524 - val_accuracy: 0.7059\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5500 - accuracy: 0.7409 - val_loss: 0.5753 - val_accuracy: 0.6935\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5583 - accuracy: 0.7409 - val_loss: 0.5489 - val_accuracy: 0.7245\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5551 - accuracy: 0.7358 - val_loss: 0.5584 - val_accuracy: 0.7059\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5426 - accuracy: 0.7547 - val_loss: 0.5615 - val_accuracy: 0.6966\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5438 - accuracy: 0.7542 - val_loss: 0.5531 - val_accuracy: 0.7059\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5497 - accuracy: 0.7450 - val_loss: 0.5516 - val_accuracy: 0.7090\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5429 - accuracy: 0.7435 - val_loss: 0.5599 - val_accuracy: 0.6904\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5387 - accuracy: 0.7537 - val_loss: 0.5507 - val_accuracy: 0.7121\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5387 - accuracy: 0.7522 - val_loss: 0.5649 - val_accuracy: 0.6873\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5361 - accuracy: 0.7460 - val_loss: 0.5556 - val_accuracy: 0.6873\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5360 - accuracy: 0.7588 - val_loss: 0.5477 - val_accuracy: 0.7059\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5485 - accuracy: 0.7547 - val_loss: 0.5653 - val_accuracy: 0.6904\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5368 - accuracy: 0.7557 - val_loss: 0.5528 - val_accuracy: 0.7028\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5313 - accuracy: 0.7517 - val_loss: 0.5288 - val_accuracy: 0.7183\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5494 - accuracy: 0.7389 - val_loss: 0.5449 - val_accuracy: 0.7152\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5237 - accuracy: 0.7787 - val_loss: 0.5578 - val_accuracy: 0.7028\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5339 - accuracy: 0.7680 - val_loss: 0.5426 - val_accuracy: 0.7090\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5374 - accuracy: 0.7517 - val_loss: 0.5576 - val_accuracy: 0.6935\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5139 - accuracy: 0.7761 - val_loss: 0.5764 - val_accuracy: 0.6873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5293 - accuracy: 0.7542 - val_loss: 0.5720 - val_accuracy: 0.6904\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5309 - accuracy: 0.7772 - val_loss: 0.5356 - val_accuracy: 0.7183\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5298 - accuracy: 0.7721 - val_loss: 0.5644 - val_accuracy: 0.7090\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5291 - accuracy: 0.7527 - val_loss: 0.5724 - val_accuracy: 0.6904\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5241 - accuracy: 0.7629 - val_loss: 0.5475 - val_accuracy: 0.7121\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5200 - accuracy: 0.7680 - val_loss: 0.5768 - val_accuracy: 0.6749\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5262 - accuracy: 0.7547 - val_loss: 0.5163 - val_accuracy: 0.7337\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5313 - accuracy: 0.7624 - val_loss: 0.5197 - val_accuracy: 0.7337\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5140 - accuracy: 0.7700 - val_loss: 0.5281 - val_accuracy: 0.7276\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5175 - accuracy: 0.7751 - val_loss: 0.5397 - val_accuracy: 0.7214\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.7680 - val_loss: 0.5699 - val_accuracy: 0.6904\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5108 - accuracy: 0.7721 - val_loss: 0.5184 - val_accuracy: 0.7307\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.7715 - val_loss: 0.5717 - val_accuracy: 0.6904\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7659 - val_loss: 0.5308 - val_accuracy: 0.7183\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5323 - accuracy: 0.7649 - val_loss: 0.5341 - val_accuracy: 0.7183\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5182 - accuracy: 0.7741 - val_loss: 0.5431 - val_accuracy: 0.7121\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5127 - accuracy: 0.7746 - val_loss: 0.5340 - val_accuracy: 0.7090\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5272 - accuracy: 0.7695 - val_loss: 0.5423 - val_accuracy: 0.7183\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7710 - val_loss: 0.5080 - val_accuracy: 0.7492\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5189 - accuracy: 0.7756 - val_loss: 0.5804 - val_accuracy: 0.6780\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5139 - accuracy: 0.7705 - val_loss: 0.5699 - val_accuracy: 0.6997\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5171 - accuracy: 0.7777 - val_loss: 0.5417 - val_accuracy: 0.7028\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7782 - val_loss: 0.5298 - val_accuracy: 0.7090\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5118 - accuracy: 0.7772 - val_loss: 0.5439 - val_accuracy: 0.7121\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5246 - accuracy: 0.7695 - val_loss: 0.5566 - val_accuracy: 0.7059\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.7812 - val_loss: 0.5573 - val_accuracy: 0.7028\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4964 - accuracy: 0.7940 - val_loss: 0.5662 - val_accuracy: 0.6997\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5209 - accuracy: 0.7721 - val_loss: 0.5334 - val_accuracy: 0.7121\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7787 - val_loss: 0.5560 - val_accuracy: 0.6904\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5172 - accuracy: 0.7736 - val_loss: 0.5364 - val_accuracy: 0.7090\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5017 - accuracy: 0.7807 - val_loss: 0.5386 - val_accuracy: 0.7183\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5132 - accuracy: 0.7812 - val_loss: 0.5433 - val_accuracy: 0.7152\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5093 - accuracy: 0.7756 - val_loss: 0.5381 - val_accuracy: 0.7183\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5104 - accuracy: 0.7802 - val_loss: 0.5181 - val_accuracy: 0.7276\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7624 - val_loss: 0.5590 - val_accuracy: 0.6997\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4985 - accuracy: 0.7838 - val_loss: 0.5059 - val_accuracy: 0.7492\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7817 - val_loss: 0.5404 - val_accuracy: 0.7090\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7746 - val_loss: 0.5188 - val_accuracy: 0.7368\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5059 - accuracy: 0.7756 - val_loss: 0.5486 - val_accuracy: 0.7059\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5011 - accuracy: 0.7879 - val_loss: 0.5753 - val_accuracy: 0.6966\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5082 - accuracy: 0.7705 - val_loss: 0.5358 - val_accuracy: 0.7121\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4966 - accuracy: 0.7889 - val_loss: 0.5689 - val_accuracy: 0.6935\n"
     ]
    }
   ],
   "source": [
    "history = model2.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "21c61d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5010 - accuracy: 0.7909\n",
      "Test Accuracy: 79.09%\n"
     ]
    }
   ],
   "source": [
    "#y_valid = tf.keras.utils.to_categorical(y_val)\n",
    "test_loss, test_acc = model2.evaluate(X_val, y_val)\n",
    "print('Test Accuracy: {:.2f}%'.format(test_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d07e40bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = tf.keras.Sequential()\n",
    "model3.add(tf.keras.layers.Dense(64, activation='relu', input_shape=(8,)))\n",
    "model3.add(tf.keras.layers.Dropout(0.5))\n",
    "model3.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model3.add(tf.keras.layers.Dropout(0.5))\n",
    "model3.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model3.add(tf.keras.layers.Dropout(0.5))\n",
    "model3.add(tf.keras.layers.Dense(4, activation='softmax'))\n",
    "model3.add(tf.keras.layers.Dropout(0.5))\n",
    "model3.add(tf.keras.layers.Dense(2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c4eda1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8350bd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "62/62 [==============================] - 2s 7ms/step - loss: 0.7196 - accuracy: 0.5110 - val_loss: 0.6707 - val_accuracy: 0.6502\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.7088 - accuracy: 0.5140 - val_loss: 0.6779 - val_accuracy: 0.6502\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.7085 - accuracy: 0.4931 - val_loss: 0.6845 - val_accuracy: 0.6502\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.7081 - accuracy: 0.5069 - val_loss: 0.6863 - val_accuracy: 0.5789\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.7088 - accuracy: 0.4895 - val_loss: 0.6880 - val_accuracy: 0.5913\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.7029 - accuracy: 0.4926 - val_loss: 0.6887 - val_accuracy: 0.5882\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.7009 - accuracy: 0.5150 - val_loss: 0.6917 - val_accuracy: 0.5913\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.7000 - accuracy: 0.5135 - val_loss: 0.6911 - val_accuracy: 0.6099\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6945 - accuracy: 0.5181 - val_loss: 0.6886 - val_accuracy: 0.6378\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6968 - accuracy: 0.5232 - val_loss: 0.6851 - val_accuracy: 0.6006\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6897 - accuracy: 0.5446 - val_loss: 0.6809 - val_accuracy: 0.5975\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6825 - accuracy: 0.5655 - val_loss: 0.6786 - val_accuracy: 0.6502\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6866 - accuracy: 0.5344 - val_loss: 0.6733 - val_accuracy: 0.6502\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6917 - accuracy: 0.5176 - val_loss: 0.6728 - val_accuracy: 0.6006\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6859 - accuracy: 0.5518 - val_loss: 0.6694 - val_accuracy: 0.6254\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6790 - accuracy: 0.5655 - val_loss: 0.6635 - val_accuracy: 0.6873\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6816 - accuracy: 0.5548 - val_loss: 0.6646 - val_accuracy: 0.6625\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6727 - accuracy: 0.5859 - val_loss: 0.6616 - val_accuracy: 0.6378\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6697 - accuracy: 0.5737 - val_loss: 0.6480 - val_accuracy: 0.6687\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6719 - accuracy: 0.5788 - val_loss: 0.6402 - val_accuracy: 0.7090\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6681 - accuracy: 0.5895 - val_loss: 0.6673 - val_accuracy: 0.5975\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6664 - accuracy: 0.5859 - val_loss: 0.6431 - val_accuracy: 0.6687\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6583 - accuracy: 0.5966 - val_loss: 0.6452 - val_accuracy: 0.6502\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6615 - accuracy: 0.5941 - val_loss: 0.6254 - val_accuracy: 0.6935\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6521 - accuracy: 0.5977 - val_loss: 0.6506 - val_accuracy: 0.6347\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6581 - accuracy: 0.5931 - val_loss: 0.6280 - val_accuracy: 0.6811\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6564 - accuracy: 0.6028 - val_loss: 0.6320 - val_accuracy: 0.6811\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6513 - accuracy: 0.6099 - val_loss: 0.6455 - val_accuracy: 0.6502\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6490 - accuracy: 0.6211 - val_loss: 0.6302 - val_accuracy: 0.6811\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6396 - accuracy: 0.6313 - val_loss: 0.6238 - val_accuracy: 0.6718\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6475 - accuracy: 0.6063 - val_loss: 0.6061 - val_accuracy: 0.7059\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6486 - accuracy: 0.6053 - val_loss: 0.6231 - val_accuracy: 0.6749\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6311 - accuracy: 0.6364 - val_loss: 0.6089 - val_accuracy: 0.6997\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6414 - accuracy: 0.6339 - val_loss: 0.6221 - val_accuracy: 0.6811\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6417 - accuracy: 0.6257 - val_loss: 0.6127 - val_accuracy: 0.6904\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6345 - accuracy: 0.6160 - val_loss: 0.6207 - val_accuracy: 0.6780\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6329 - accuracy: 0.6349 - val_loss: 0.6233 - val_accuracy: 0.6749\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6291 - accuracy: 0.6272 - val_loss: 0.6048 - val_accuracy: 0.7028\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6295 - accuracy: 0.6247 - val_loss: 0.6144 - val_accuracy: 0.6811\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6313 - accuracy: 0.6216 - val_loss: 0.6022 - val_accuracy: 0.6966\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6364 - accuracy: 0.6283 - val_loss: 0.6063 - val_accuracy: 0.6904\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6131 - accuracy: 0.6476 - val_loss: 0.6170 - val_accuracy: 0.6718\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6189 - accuracy: 0.6410 - val_loss: 0.6065 - val_accuracy: 0.6935\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6263 - accuracy: 0.6267 - val_loss: 0.6014 - val_accuracy: 0.6935\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6308 - accuracy: 0.6364 - val_loss: 0.6011 - val_accuracy: 0.6842\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6115 - accuracy: 0.6588 - val_loss: 0.5920 - val_accuracy: 0.6997\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6201 - accuracy: 0.6420 - val_loss: 0.6099 - val_accuracy: 0.6749\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6212 - accuracy: 0.6492 - val_loss: 0.6059 - val_accuracy: 0.6811\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6087 - accuracy: 0.6497 - val_loss: 0.5830 - val_accuracy: 0.6997\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6139 - accuracy: 0.6390 - val_loss: 0.5982 - val_accuracy: 0.6966\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6234 - accuracy: 0.6313 - val_loss: 0.5973 - val_accuracy: 0.6997\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6084 - accuracy: 0.6507 - val_loss: 0.5894 - val_accuracy: 0.6966\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6095 - accuracy: 0.6680 - val_loss: 0.5940 - val_accuracy: 0.6904\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6299 - accuracy: 0.6323 - val_loss: 0.5968 - val_accuracy: 0.6780\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6239 - accuracy: 0.6369 - val_loss: 0.5988 - val_accuracy: 0.6904\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6144 - accuracy: 0.6619 - val_loss: 0.5911 - val_accuracy: 0.6997\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6054 - accuracy: 0.6563 - val_loss: 0.5836 - val_accuracy: 0.6997\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5989 - accuracy: 0.6568 - val_loss: 0.5977 - val_accuracy: 0.6842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6198 - accuracy: 0.6410 - val_loss: 0.6052 - val_accuracy: 0.6687\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6047 - accuracy: 0.6497 - val_loss: 0.6001 - val_accuracy: 0.6811\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6085 - accuracy: 0.6492 - val_loss: 0.6014 - val_accuracy: 0.6749\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6089 - accuracy: 0.6634 - val_loss: 0.6007 - val_accuracy: 0.6749\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6033 - accuracy: 0.6563 - val_loss: 0.6034 - val_accuracy: 0.6718\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6010 - accuracy: 0.6486 - val_loss: 0.5950 - val_accuracy: 0.6935\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6134 - accuracy: 0.6492 - val_loss: 0.5866 - val_accuracy: 0.6873\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6000 - accuracy: 0.6553 - val_loss: 0.5898 - val_accuracy: 0.6935\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5989 - accuracy: 0.6578 - val_loss: 0.5892 - val_accuracy: 0.6780\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6053 - accuracy: 0.6568 - val_loss: 0.5894 - val_accuracy: 0.6873\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6073 - accuracy: 0.6543 - val_loss: 0.6000 - val_accuracy: 0.6811\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6073 - accuracy: 0.6446 - val_loss: 0.6064 - val_accuracy: 0.6656\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5917 - accuracy: 0.6650 - val_loss: 0.5920 - val_accuracy: 0.6873\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6064 - accuracy: 0.6410 - val_loss: 0.5921 - val_accuracy: 0.6904\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6103 - accuracy: 0.6446 - val_loss: 0.6071 - val_accuracy: 0.6687\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5976 - accuracy: 0.6619 - val_loss: 0.6015 - val_accuracy: 0.6811\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5911 - accuracy: 0.6726 - val_loss: 0.5992 - val_accuracy: 0.6780\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5878 - accuracy: 0.6609 - val_loss: 0.5908 - val_accuracy: 0.6873\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6049 - accuracy: 0.6517 - val_loss: 0.5790 - val_accuracy: 0.6997\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5910 - accuracy: 0.6660 - val_loss: 0.5867 - val_accuracy: 0.6687\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5788 - accuracy: 0.6685 - val_loss: 0.5911 - val_accuracy: 0.6966\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5882 - accuracy: 0.6696 - val_loss: 0.5949 - val_accuracy: 0.6842\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5908 - accuracy: 0.6517 - val_loss: 0.5756 - val_accuracy: 0.7059\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5958 - accuracy: 0.6548 - val_loss: 0.5801 - val_accuracy: 0.6904\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5986 - accuracy: 0.6711 - val_loss: 0.5552 - val_accuracy: 0.7028\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5866 - accuracy: 0.6726 - val_loss: 0.5869 - val_accuracy: 0.7028\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5960 - accuracy: 0.6527 - val_loss: 0.5822 - val_accuracy: 0.6966\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5976 - accuracy: 0.6548 - val_loss: 0.5903 - val_accuracy: 0.6749\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5793 - accuracy: 0.6655 - val_loss: 0.5836 - val_accuracy: 0.6873\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5904 - accuracy: 0.6537 - val_loss: 0.5801 - val_accuracy: 0.6935\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5820 - accuracy: 0.6690 - val_loss: 0.5801 - val_accuracy: 0.6997\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5884 - accuracy: 0.6548 - val_loss: 0.5612 - val_accuracy: 0.7152\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5825 - accuracy: 0.6675 - val_loss: 0.5779 - val_accuracy: 0.6904\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5958 - accuracy: 0.6481 - val_loss: 0.5765 - val_accuracy: 0.6966\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5734 - accuracy: 0.6803 - val_loss: 0.5735 - val_accuracy: 0.6966\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6002 - accuracy: 0.6527 - val_loss: 0.5655 - val_accuracy: 0.6935\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5804 - accuracy: 0.6639 - val_loss: 0.5665 - val_accuracy: 0.6873\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5794 - accuracy: 0.6798 - val_loss: 0.5770 - val_accuracy: 0.6904\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5843 - accuracy: 0.6690 - val_loss: 0.5691 - val_accuracy: 0.6966\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5937 - accuracy: 0.6430 - val_loss: 0.5857 - val_accuracy: 0.6811\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5781 - accuracy: 0.6578 - val_loss: 0.5713 - val_accuracy: 0.6935\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5849 - accuracy: 0.6619 - val_loss: 0.5521 - val_accuracy: 0.7121\n"
     ]
    }
   ],
   "source": [
    "history = model3.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7d95ff2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.8121\n",
      "Test Accuracy: 81.21%\n"
     ]
    }
   ],
   "source": [
    "#y_valid = tf.keras.utils.to_categorical(y_val)\n",
    "test_loss, test_acc = model3.evaluate(X_val, y_val)\n",
    "print('Test Accuracy: {:.2f}%'.format(test_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9f9fae3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = tf.keras.Sequential()\n",
    "model4.add(tf.keras.layers.Dense(64, activation='relu', input_shape=(8,)))\n",
    "model4.add(tf.keras.layers.Dropout(0.5))\n",
    "model4.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model4.add(tf.keras.layers.Dropout(0.5))\n",
    "model4.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "model4.add(tf.keras.layers.Dropout(0.5))\n",
    "model4.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model4.add(tf.keras.layers.Dropout(0.2))\n",
    "model4.add(tf.keras.layers.Dense(4, activation='softmax'))\n",
    "model4.add(tf.keras.layers.Dropout(0.2))\n",
    "model4.add(tf.keras.layers.Dense(2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "36c36a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6c506ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "62/62 [==============================] - 2s 7ms/step - loss: 0.6957 - accuracy: 0.5186 - val_loss: 0.6858 - val_accuracy: 0.6502\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6973 - accuracy: 0.5069 - val_loss: 0.6848 - val_accuracy: 0.6471\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6890 - accuracy: 0.5385 - val_loss: 0.6817 - val_accuracy: 0.6037\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6967 - accuracy: 0.5196 - val_loss: 0.6816 - val_accuracy: 0.6099\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5375 - val_loss: 0.6816 - val_accuracy: 0.5913\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6846 - accuracy: 0.5732 - val_loss: 0.6761 - val_accuracy: 0.6161\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6810 - accuracy: 0.5813 - val_loss: 0.6725 - val_accuracy: 0.7183\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6790 - accuracy: 0.5844 - val_loss: 0.6675 - val_accuracy: 0.7399\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6806 - accuracy: 0.5716 - val_loss: 0.6617 - val_accuracy: 0.7245\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6730 - accuracy: 0.5783 - val_loss: 0.6542 - val_accuracy: 0.7276\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6640 - accuracy: 0.6140 - val_loss: 0.6480 - val_accuracy: 0.7152\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6539 - accuracy: 0.6293 - val_loss: 0.6428 - val_accuracy: 0.7028\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6498 - accuracy: 0.6308 - val_loss: 0.6295 - val_accuracy: 0.7152\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6476 - accuracy: 0.6267 - val_loss: 0.6209 - val_accuracy: 0.7214\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6474 - accuracy: 0.6232 - val_loss: 0.6132 - val_accuracy: 0.7307\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6352 - accuracy: 0.6446 - val_loss: 0.6189 - val_accuracy: 0.7183\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6266 - accuracy: 0.6476 - val_loss: 0.5983 - val_accuracy: 0.7523\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6251 - accuracy: 0.6481 - val_loss: 0.5996 - val_accuracy: 0.7368\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6262 - accuracy: 0.6451 - val_loss: 0.5947 - val_accuracy: 0.7430\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6186 - accuracy: 0.6573 - val_loss: 0.6122 - val_accuracy: 0.7090\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6125 - accuracy: 0.6675 - val_loss: 0.5884 - val_accuracy: 0.7337\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6149 - accuracy: 0.6583 - val_loss: 0.5837 - val_accuracy: 0.7337\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6076 - accuracy: 0.6696 - val_loss: 0.5685 - val_accuracy: 0.7647\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6023 - accuracy: 0.6813 - val_loss: 0.6019 - val_accuracy: 0.7183\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6015 - accuracy: 0.6803 - val_loss: 0.5631 - val_accuracy: 0.7523\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5897 - accuracy: 0.6945 - val_loss: 0.6022 - val_accuracy: 0.7214\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5999 - accuracy: 0.6757 - val_loss: 0.5697 - val_accuracy: 0.7585\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5875 - accuracy: 0.6869 - val_loss: 0.5825 - val_accuracy: 0.7307\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5879 - accuracy: 0.6884 - val_loss: 0.5688 - val_accuracy: 0.7430\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5897 - accuracy: 0.6961 - val_loss: 0.5687 - val_accuracy: 0.7337\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5776 - accuracy: 0.7104 - val_loss: 0.5738 - val_accuracy: 0.7214\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5700 - accuracy: 0.7216 - val_loss: 0.5746 - val_accuracy: 0.7245\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5870 - accuracy: 0.7012 - val_loss: 0.5675 - val_accuracy: 0.7245\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5678 - accuracy: 0.7200 - val_loss: 0.5826 - val_accuracy: 0.7307\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5654 - accuracy: 0.7180 - val_loss: 0.5909 - val_accuracy: 0.7214\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5794 - accuracy: 0.7165 - val_loss: 0.6145 - val_accuracy: 0.6997\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5763 - accuracy: 0.7206 - val_loss: 0.5884 - val_accuracy: 0.7183\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5860 - accuracy: 0.7180 - val_loss: 0.6199 - val_accuracy: 0.6904\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5579 - accuracy: 0.7511 - val_loss: 0.5739 - val_accuracy: 0.7337\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5675 - accuracy: 0.7343 - val_loss: 0.5892 - val_accuracy: 0.7090\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5667 - accuracy: 0.7323 - val_loss: 0.5538 - val_accuracy: 0.7307\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5711 - accuracy: 0.7313 - val_loss: 0.6014 - val_accuracy: 0.6904\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5574 - accuracy: 0.7547 - val_loss: 0.5834 - val_accuracy: 0.7183\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5754 - accuracy: 0.7302 - val_loss: 0.5773 - val_accuracy: 0.7183\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5566 - accuracy: 0.7455 - val_loss: 0.5741 - val_accuracy: 0.7214\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5482 - accuracy: 0.7659 - val_loss: 0.5984 - val_accuracy: 0.6904\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5479 - accuracy: 0.7593 - val_loss: 0.5853 - val_accuracy: 0.7152\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5448 - accuracy: 0.7583 - val_loss: 0.6297 - val_accuracy: 0.6873\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5601 - accuracy: 0.7491 - val_loss: 0.5587 - val_accuracy: 0.7461\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5493 - accuracy: 0.7542 - val_loss: 0.6059 - val_accuracy: 0.6997\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5583 - accuracy: 0.7415 - val_loss: 0.5922 - val_accuracy: 0.7059\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5603 - accuracy: 0.7353 - val_loss: 0.6101 - val_accuracy: 0.6811\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5514 - accuracy: 0.7460 - val_loss: 0.5829 - val_accuracy: 0.7028\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5608 - accuracy: 0.7532 - val_loss: 0.6063 - val_accuracy: 0.6842\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5447 - accuracy: 0.7501 - val_loss: 0.5876 - val_accuracy: 0.6997\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5529 - accuracy: 0.7415 - val_loss: 0.5944 - val_accuracy: 0.6966\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5284 - accuracy: 0.7634 - val_loss: 0.5779 - val_accuracy: 0.6873\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5391 - accuracy: 0.7680 - val_loss: 0.5679 - val_accuracy: 0.7121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5340 - accuracy: 0.7695 - val_loss: 0.5645 - val_accuracy: 0.7399\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5341 - accuracy: 0.7583 - val_loss: 0.5780 - val_accuracy: 0.7307\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5504 - accuracy: 0.7496 - val_loss: 0.5798 - val_accuracy: 0.7121\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5419 - accuracy: 0.7568 - val_loss: 0.5744 - val_accuracy: 0.7245\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5356 - accuracy: 0.7624 - val_loss: 0.5772 - val_accuracy: 0.7245\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5415 - accuracy: 0.7583 - val_loss: 0.5421 - val_accuracy: 0.7523\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5353 - accuracy: 0.7629 - val_loss: 0.5845 - val_accuracy: 0.7059\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5276 - accuracy: 0.7634 - val_loss: 0.5746 - val_accuracy: 0.7090\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5331 - accuracy: 0.7634 - val_loss: 0.5657 - val_accuracy: 0.7245\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5302 - accuracy: 0.7670 - val_loss: 0.5801 - val_accuracy: 0.7059\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5418 - accuracy: 0.7552 - val_loss: 0.5754 - val_accuracy: 0.7059\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5190 - accuracy: 0.7731 - val_loss: 0.5877 - val_accuracy: 0.6997\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5146 - accuracy: 0.7710 - val_loss: 0.5610 - val_accuracy: 0.7276\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5200 - accuracy: 0.7715 - val_loss: 0.5953 - val_accuracy: 0.7059\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5098 - accuracy: 0.7802 - val_loss: 0.5463 - val_accuracy: 0.7337\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5234 - accuracy: 0.7736 - val_loss: 0.5842 - val_accuracy: 0.6997\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5194 - accuracy: 0.7654 - val_loss: 0.5807 - val_accuracy: 0.6997\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5596 - accuracy: 0.7379 - val_loss: 0.5640 - val_accuracy: 0.7090\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5230 - accuracy: 0.7736 - val_loss: 0.5448 - val_accuracy: 0.7492\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5289 - accuracy: 0.7680 - val_loss: 0.5947 - val_accuracy: 0.6904\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5298 - accuracy: 0.7639 - val_loss: 0.5699 - val_accuracy: 0.6935\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5208 - accuracy: 0.7710 - val_loss: 0.5690 - val_accuracy: 0.6997\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5268 - accuracy: 0.7664 - val_loss: 0.5781 - val_accuracy: 0.6997\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5198 - accuracy: 0.7787 - val_loss: 0.5643 - val_accuracy: 0.7276\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5265 - accuracy: 0.7690 - val_loss: 0.6025 - val_accuracy: 0.6966\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5274 - accuracy: 0.7644 - val_loss: 0.5643 - val_accuracy: 0.7183\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5154 - accuracy: 0.7736 - val_loss: 0.5739 - val_accuracy: 0.7214\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5138 - accuracy: 0.7746 - val_loss: 0.5586 - val_accuracy: 0.7090\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5210 - accuracy: 0.7603 - val_loss: 0.5680 - val_accuracy: 0.7183\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5178 - accuracy: 0.7772 - val_loss: 0.5430 - val_accuracy: 0.7368\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5020 - accuracy: 0.7823 - val_loss: 0.5652 - val_accuracy: 0.7337\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5207 - accuracy: 0.7695 - val_loss: 0.5798 - val_accuracy: 0.7028\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5257 - accuracy: 0.7731 - val_loss: 0.5383 - val_accuracy: 0.7183\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5129 - accuracy: 0.7772 - val_loss: 0.5875 - val_accuracy: 0.6935\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5099 - accuracy: 0.7761 - val_loss: 0.5881 - val_accuracy: 0.6873\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5013 - accuracy: 0.7797 - val_loss: 0.5949 - val_accuracy: 0.6966\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5184 - accuracy: 0.7731 - val_loss: 0.5912 - val_accuracy: 0.6997\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5096 - accuracy: 0.7726 - val_loss: 0.5399 - val_accuracy: 0.7337\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5155 - accuracy: 0.7731 - val_loss: 0.5722 - val_accuracy: 0.6935\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5132 - accuracy: 0.7746 - val_loss: 0.5585 - val_accuracy: 0.7059\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5108 - accuracy: 0.7807 - val_loss: 0.5480 - val_accuracy: 0.7399\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5196 - accuracy: 0.7715 - val_loss: 0.5224 - val_accuracy: 0.7399\n"
     ]
    }
   ],
   "source": [
    "history = model4.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a65afe4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5337 - accuracy: 0.7576\n",
      "Test Accuracy: 75.76%\n"
     ]
    }
   ],
   "source": [
    "#y_valid = tf.keras.utils.to_categorical(y_val)\n",
    "test_loss, test_acc = model4.evaluate(X_val, y_val)\n",
    "print('Test Accuracy: {:.2f}%'.format(test_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "61dacd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = tf.keras.Sequential()\n",
    "model5.add(tf.keras.layers.Dense(64, activation='relu', input_shape=(8,)))\n",
    "model5.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model5.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "model5.add(tf.keras.layers.Dropout(0.5))\n",
    "model5.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model5.add(tf.keras.layers.Dense(4, activation='softmax'))\n",
    "model5.add(tf.keras.layers.Dense(2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0a9ae44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model5.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3bdea4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "62/62 [==============================] - 2s 7ms/step - loss: 0.7264 - accuracy: 0.5059 - val_loss: 0.6556 - val_accuracy: 0.6502\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.7010 - accuracy: 0.5059 - val_loss: 0.6766 - val_accuracy: 0.6502\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6948 - accuracy: 0.5059 - val_loss: 0.6849 - val_accuracy: 0.6502\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5059 - val_loss: 0.6742 - val_accuracy: 0.6502\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6778 - accuracy: 0.5711 - val_loss: 0.6735 - val_accuracy: 0.6223\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6637 - accuracy: 0.6660 - val_loss: 0.6446 - val_accuracy: 0.6749\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6448 - accuracy: 0.7053 - val_loss: 0.6253 - val_accuracy: 0.7183\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6270 - accuracy: 0.7058 - val_loss: 0.6404 - val_accuracy: 0.6316\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6040 - accuracy: 0.7262 - val_loss: 0.5871 - val_accuracy: 0.6997\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5895 - accuracy: 0.7358 - val_loss: 0.6079 - val_accuracy: 0.6625\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5764 - accuracy: 0.7409 - val_loss: 0.5805 - val_accuracy: 0.7121\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5637 - accuracy: 0.7517 - val_loss: 0.5987 - val_accuracy: 0.6749\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5496 - accuracy: 0.7593 - val_loss: 0.5570 - val_accuracy: 0.7183\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5517 - accuracy: 0.7547 - val_loss: 0.6215 - val_accuracy: 0.6687\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5337 - accuracy: 0.7731 - val_loss: 0.5875 - val_accuracy: 0.6997\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5353 - accuracy: 0.7705 - val_loss: 0.5836 - val_accuracy: 0.6997\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5268 - accuracy: 0.7721 - val_loss: 0.5988 - val_accuracy: 0.6997\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5227 - accuracy: 0.7721 - val_loss: 0.5960 - val_accuracy: 0.7059\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5200 - accuracy: 0.7777 - val_loss: 0.5920 - val_accuracy: 0.6935\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5192 - accuracy: 0.7700 - val_loss: 0.6242 - val_accuracy: 0.6563\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5127 - accuracy: 0.7848 - val_loss: 0.5844 - val_accuracy: 0.7152\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5104 - accuracy: 0.7715 - val_loss: 0.6309 - val_accuracy: 0.6718\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5048 - accuracy: 0.7812 - val_loss: 0.6291 - val_accuracy: 0.6687\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5023 - accuracy: 0.7751 - val_loss: 0.5669 - val_accuracy: 0.7183\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4941 - accuracy: 0.7874 - val_loss: 0.5706 - val_accuracy: 0.7090\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4833 - accuracy: 0.7858 - val_loss: 0.5753 - val_accuracy: 0.7121\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4759 - accuracy: 0.7925 - val_loss: 0.5892 - val_accuracy: 0.7028\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4690 - accuracy: 0.7970 - val_loss: 0.5830 - val_accuracy: 0.6966\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4969 - accuracy: 0.7731 - val_loss: 0.5806 - val_accuracy: 0.7090\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4533 - accuracy: 0.8108 - val_loss: 0.5625 - val_accuracy: 0.7121\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.8006 - val_loss: 0.5751 - val_accuracy: 0.7028\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4681 - accuracy: 0.8032 - val_loss: 0.4895 - val_accuracy: 0.7926\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4569 - accuracy: 0.8057 - val_loss: 0.5282 - val_accuracy: 0.7399\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4535 - accuracy: 0.8052 - val_loss: 0.6135 - val_accuracy: 0.6966\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4476 - accuracy: 0.8205 - val_loss: 0.5983 - val_accuracy: 0.7059\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.8164 - val_loss: 0.5680 - val_accuracy: 0.7090\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.8118 - val_loss: 0.5821 - val_accuracy: 0.7028\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4414 - accuracy: 0.8134 - val_loss: 0.5387 - val_accuracy: 0.7337\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4305 - accuracy: 0.8215 - val_loss: 0.4832 - val_accuracy: 0.7802\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.8210 - val_loss: 0.5149 - val_accuracy: 0.7461\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4250 - accuracy: 0.8256 - val_loss: 0.4850 - val_accuracy: 0.7709\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.8215 - val_loss: 0.5368 - val_accuracy: 0.7461\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4290 - accuracy: 0.8225 - val_loss: 0.5168 - val_accuracy: 0.7740\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4409 - accuracy: 0.8149 - val_loss: 0.4977 - val_accuracy: 0.7709\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.8220 - val_loss: 0.5600 - val_accuracy: 0.7368\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4403 - accuracy: 0.8200 - val_loss: 0.4967 - val_accuracy: 0.7554\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4207 - accuracy: 0.8343 - val_loss: 0.5546 - val_accuracy: 0.7337\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.8225 - val_loss: 0.5160 - val_accuracy: 0.7554\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4349 - accuracy: 0.8190 - val_loss: 0.5867 - val_accuracy: 0.7245\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4124 - accuracy: 0.8322 - val_loss: 0.5815 - val_accuracy: 0.7214\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4104 - accuracy: 0.8348 - val_loss: 0.5003 - val_accuracy: 0.7926\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.8134 - val_loss: 0.5358 - val_accuracy: 0.7554\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4093 - accuracy: 0.8368 - val_loss: 0.5663 - val_accuracy: 0.7121\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4100 - accuracy: 0.8373 - val_loss: 0.5529 - val_accuracy: 0.7307\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4161 - accuracy: 0.8281 - val_loss: 0.4918 - val_accuracy: 0.7678\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4092 - accuracy: 0.8368 - val_loss: 0.5144 - val_accuracy: 0.7740\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4023 - accuracy: 0.8383 - val_loss: 0.5009 - val_accuracy: 0.7895\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4019 - accuracy: 0.8373 - val_loss: 0.5580 - val_accuracy: 0.7337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4020 - accuracy: 0.8378 - val_loss: 0.6056 - val_accuracy: 0.7152\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4036 - accuracy: 0.8348 - val_loss: 0.5652 - val_accuracy: 0.7430\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4093 - accuracy: 0.8353 - val_loss: 0.6732 - val_accuracy: 0.6811\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3952 - accuracy: 0.8440 - val_loss: 0.5888 - val_accuracy: 0.7152\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3950 - accuracy: 0.8404 - val_loss: 0.5613 - val_accuracy: 0.7430\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3997 - accuracy: 0.8389 - val_loss: 0.5708 - val_accuracy: 0.7276\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.3810 - accuracy: 0.8496 - val_loss: 0.5810 - val_accuracy: 0.7307\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3926 - accuracy: 0.8496 - val_loss: 0.5766 - val_accuracy: 0.7430\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.3903 - accuracy: 0.8440 - val_loss: 0.4955 - val_accuracy: 0.8019\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3860 - accuracy: 0.8531 - val_loss: 0.5282 - val_accuracy: 0.7492\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3906 - accuracy: 0.8440 - val_loss: 0.6175 - val_accuracy: 0.7090\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3854 - accuracy: 0.8506 - val_loss: 0.5442 - val_accuracy: 0.7585\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3843 - accuracy: 0.8465 - val_loss: 0.5139 - val_accuracy: 0.7740\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3672 - accuracy: 0.8618 - val_loss: 0.5367 - val_accuracy: 0.7554\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3705 - accuracy: 0.8582 - val_loss: 0.6073 - val_accuracy: 0.7307\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.3854 - accuracy: 0.8455 - val_loss: 0.5691 - val_accuracy: 0.7492\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.3813 - accuracy: 0.8516 - val_loss: 0.4976 - val_accuracy: 0.7709\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3767 - accuracy: 0.8506 - val_loss: 0.4828 - val_accuracy: 0.8080\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3788 - accuracy: 0.8475 - val_loss: 0.6528 - val_accuracy: 0.6997\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3684 - accuracy: 0.8598 - val_loss: 0.5712 - val_accuracy: 0.7399\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3688 - accuracy: 0.8618 - val_loss: 0.5952 - val_accuracy: 0.7337\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.3700 - accuracy: 0.8572 - val_loss: 0.6062 - val_accuracy: 0.7307\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3598 - accuracy: 0.8664 - val_loss: 0.6097 - val_accuracy: 0.7121\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.3636 - accuracy: 0.8562 - val_loss: 0.5743 - val_accuracy: 0.7523\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3731 - accuracy: 0.8552 - val_loss: 0.6156 - val_accuracy: 0.7152\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3558 - accuracy: 0.8700 - val_loss: 0.6232 - val_accuracy: 0.7276\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3574 - accuracy: 0.8679 - val_loss: 0.6240 - val_accuracy: 0.7245\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.3633 - accuracy: 0.8593 - val_loss: 0.5401 - val_accuracy: 0.7492\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3713 - accuracy: 0.8526 - val_loss: 0.5465 - val_accuracy: 0.7709\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.3590 - accuracy: 0.8608 - val_loss: 0.6535 - val_accuracy: 0.6842\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3633 - accuracy: 0.8613 - val_loss: 0.6327 - val_accuracy: 0.6904\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3669 - accuracy: 0.8552 - val_loss: 0.5989 - val_accuracy: 0.7307\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3636 - accuracy: 0.8593 - val_loss: 0.5791 - val_accuracy: 0.7276\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3554 - accuracy: 0.8669 - val_loss: 0.6115 - val_accuracy: 0.7337\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.3518 - accuracy: 0.8659 - val_loss: 0.5914 - val_accuracy: 0.7183\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3434 - accuracy: 0.8695 - val_loss: 0.7044 - val_accuracy: 0.6904\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.3498 - accuracy: 0.8715 - val_loss: 0.6389 - val_accuracy: 0.7059\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3647 - accuracy: 0.8608 - val_loss: 0.5577 - val_accuracy: 0.7616\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.3392 - accuracy: 0.8776 - val_loss: 0.6470 - val_accuracy: 0.7059\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.3386 - accuracy: 0.8766 - val_loss: 0.6015 - val_accuracy: 0.7245\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.3390 - accuracy: 0.8730 - val_loss: 0.6259 - val_accuracy: 0.7090\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3407 - accuracy: 0.8700 - val_loss: 0.6945 - val_accuracy: 0.6904\n"
     ]
    }
   ],
   "source": [
    "history = model5.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c7011ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 2ms/step - loss: 0.6061 - accuracy: 0.7576\n",
      "Test Accuracy: 75.76%\n"
     ]
    }
   ],
   "source": [
    "#y_valid = tf.keras.utils.to_categorical(y_val)\n",
    "test_loss, test_acc = model5.evaluate(X_val, y_val)\n",
    "print('Test Accuracy: {:.2f}%'.format(test_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "50b359a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = tf.keras.Sequential()\n",
    "model6.add(tf.keras.layers.Dense(64, activation='relu', input_shape=(8,)))\n",
    "model6.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model6.add(tf.keras.layers.Dropout(0.5))\n",
    "model6.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "model6.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model6.add(tf.keras.layers.Dense(4, activation='softmax'))\n",
    "model6.add(tf.keras.layers.Dropout(0.5))\n",
    "model6.add(tf.keras.layers.Dense(2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6d702934",
   "metadata": {},
   "outputs": [],
   "source": [
    "model6.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c53c015b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "62/62 [==============================] - 2s 7ms/step - loss: 0.7239 - accuracy: 0.5258 - val_loss: 0.7084 - val_accuracy: 0.3498\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.7144 - accuracy: 0.5043 - val_loss: 0.6957 - val_accuracy: 0.5573\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.5288 - val_loss: 0.6802 - val_accuracy: 0.6099\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6954 - accuracy: 0.5365 - val_loss: 0.6783 - val_accuracy: 0.6037\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6829 - accuracy: 0.5543 - val_loss: 0.6802 - val_accuracy: 0.6811\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6812 - accuracy: 0.5599 - val_loss: 0.6653 - val_accuracy: 0.6904\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6720 - accuracy: 0.5722 - val_loss: 0.6497 - val_accuracy: 0.7028\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6454 - accuracy: 0.6226 - val_loss: 0.6221 - val_accuracy: 0.7523\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6385 - accuracy: 0.6232 - val_loss: 0.6274 - val_accuracy: 0.6873\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6466 - accuracy: 0.6181 - val_loss: 0.6230 - val_accuracy: 0.7337\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6242 - accuracy: 0.6594 - val_loss: 0.6361 - val_accuracy: 0.6966\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6366 - accuracy: 0.6390 - val_loss: 0.5916 - val_accuracy: 0.7709\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6230 - accuracy: 0.6512 - val_loss: 0.5972 - val_accuracy: 0.7492\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6220 - accuracy: 0.6507 - val_loss: 0.6325 - val_accuracy: 0.7059\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6082 - accuracy: 0.6650 - val_loss: 0.5900 - val_accuracy: 0.7214\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6093 - accuracy: 0.6655 - val_loss: 0.5741 - val_accuracy: 0.7430\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6090 - accuracy: 0.6609 - val_loss: 0.6004 - val_accuracy: 0.7090\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5944 - accuracy: 0.6828 - val_loss: 0.5733 - val_accuracy: 0.7214\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6008 - accuracy: 0.6874 - val_loss: 0.5896 - val_accuracy: 0.7152\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5957 - accuracy: 0.6747 - val_loss: 0.6007 - val_accuracy: 0.6966\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5936 - accuracy: 0.6884 - val_loss: 0.5971 - val_accuracy: 0.6904\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5861 - accuracy: 0.6976 - val_loss: 0.5483 - val_accuracy: 0.7709\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5827 - accuracy: 0.6920 - val_loss: 0.5963 - val_accuracy: 0.7028\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5719 - accuracy: 0.7093 - val_loss: 0.5909 - val_accuracy: 0.6935\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5741 - accuracy: 0.7037 - val_loss: 0.5551 - val_accuracy: 0.7307\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5826 - accuracy: 0.6945 - val_loss: 0.5404 - val_accuracy: 0.7399\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5694 - accuracy: 0.7017 - val_loss: 0.5797 - val_accuracy: 0.6935\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5535 - accuracy: 0.7160 - val_loss: 0.5974 - val_accuracy: 0.6749\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5589 - accuracy: 0.7287 - val_loss: 0.5728 - val_accuracy: 0.7183\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5650 - accuracy: 0.7180 - val_loss: 0.6075 - val_accuracy: 0.6811\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5356 - accuracy: 0.7292 - val_loss: 0.5878 - val_accuracy: 0.6811\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5600 - accuracy: 0.7267 - val_loss: 0.6159 - val_accuracy: 0.6780\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5658 - accuracy: 0.7047 - val_loss: 0.5725 - val_accuracy: 0.7214\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5604 - accuracy: 0.7165 - val_loss: 0.5930 - val_accuracy: 0.6935\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5433 - accuracy: 0.7313 - val_loss: 0.6096 - val_accuracy: 0.6842\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5484 - accuracy: 0.7216 - val_loss: 0.5650 - val_accuracy: 0.7430\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5536 - accuracy: 0.7160 - val_loss: 0.5928 - val_accuracy: 0.6904\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5299 - accuracy: 0.7409 - val_loss: 0.6035 - val_accuracy: 0.6842\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5486 - accuracy: 0.7231 - val_loss: 0.5949 - val_accuracy: 0.6811\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5407 - accuracy: 0.7221 - val_loss: 0.6361 - val_accuracy: 0.6718\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5368 - accuracy: 0.7257 - val_loss: 0.5461 - val_accuracy: 0.7461\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5349 - accuracy: 0.7343 - val_loss: 0.5730 - val_accuracy: 0.7028\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5327 - accuracy: 0.7445 - val_loss: 0.5970 - val_accuracy: 0.6842\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5322 - accuracy: 0.7364 - val_loss: 0.5596 - val_accuracy: 0.7492\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5306 - accuracy: 0.7389 - val_loss: 0.5452 - val_accuracy: 0.7430\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5300 - accuracy: 0.7323 - val_loss: 0.5810 - val_accuracy: 0.6966\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5411 - accuracy: 0.7236 - val_loss: 0.5558 - val_accuracy: 0.7399\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5472 - accuracy: 0.7211 - val_loss: 0.6444 - val_accuracy: 0.6749\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5337 - accuracy: 0.7318 - val_loss: 0.5749 - val_accuracy: 0.7152\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5264 - accuracy: 0.7399 - val_loss: 0.5494 - val_accuracy: 0.7616\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5273 - accuracy: 0.7394 - val_loss: 0.5517 - val_accuracy: 0.7554\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5280 - accuracy: 0.7333 - val_loss: 0.5895 - val_accuracy: 0.6966\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5255 - accuracy: 0.7338 - val_loss: 0.5819 - val_accuracy: 0.7090\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5312 - accuracy: 0.7343 - val_loss: 0.6275 - val_accuracy: 0.6904\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5268 - accuracy: 0.7440 - val_loss: 0.5462 - val_accuracy: 0.7492\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5169 - accuracy: 0.7394 - val_loss: 0.5121 - val_accuracy: 0.7709\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5340 - accuracy: 0.7246 - val_loss: 0.6054 - val_accuracy: 0.6935\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5205 - accuracy: 0.7307 - val_loss: 0.5832 - val_accuracy: 0.7121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5221 - accuracy: 0.7394 - val_loss: 0.5583 - val_accuracy: 0.7368\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.7491 - val_loss: 0.5496 - val_accuracy: 0.7461\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5274 - accuracy: 0.7343 - val_loss: 0.6480 - val_accuracy: 0.6780\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5178 - accuracy: 0.7450 - val_loss: 0.6215 - val_accuracy: 0.6811\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5124 - accuracy: 0.7302 - val_loss: 0.6180 - val_accuracy: 0.6873\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5112 - accuracy: 0.7338 - val_loss: 0.5970 - val_accuracy: 0.6997\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5398 - accuracy: 0.7175 - val_loss: 0.5511 - val_accuracy: 0.7430\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5229 - accuracy: 0.7333 - val_loss: 0.5702 - val_accuracy: 0.7059\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5234 - accuracy: 0.7420 - val_loss: 0.5957 - val_accuracy: 0.6904\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5193 - accuracy: 0.7486 - val_loss: 0.5669 - val_accuracy: 0.7152\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5122 - accuracy: 0.7425 - val_loss: 0.5446 - val_accuracy: 0.7492\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.7425 - val_loss: 0.5996 - val_accuracy: 0.6997\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5188 - accuracy: 0.7333 - val_loss: 0.5549 - val_accuracy: 0.7337\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5188 - accuracy: 0.7343 - val_loss: 0.6083 - val_accuracy: 0.6842\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5156 - accuracy: 0.7262 - val_loss: 0.5659 - val_accuracy: 0.7337\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5164 - accuracy: 0.7455 - val_loss: 0.5837 - val_accuracy: 0.7090\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5095 - accuracy: 0.7430 - val_loss: 0.5858 - val_accuracy: 0.7152\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5163 - accuracy: 0.7374 - val_loss: 0.6038 - val_accuracy: 0.6935\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.7338 - val_loss: 0.5964 - val_accuracy: 0.7028\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5016 - accuracy: 0.7399 - val_loss: 0.5748 - val_accuracy: 0.7307\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5022 - accuracy: 0.7440 - val_loss: 0.5480 - val_accuracy: 0.7523\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4998 - accuracy: 0.7471 - val_loss: 0.6199 - val_accuracy: 0.7121\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5126 - accuracy: 0.7358 - val_loss: 0.5782 - val_accuracy: 0.7090\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4991 - accuracy: 0.7404 - val_loss: 0.5684 - val_accuracy: 0.7183\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4969 - accuracy: 0.7491 - val_loss: 0.6084 - val_accuracy: 0.6935\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4991 - accuracy: 0.7496 - val_loss: 0.5627 - val_accuracy: 0.7337\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5026 - accuracy: 0.7430 - val_loss: 0.5682 - val_accuracy: 0.7245\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5102 - accuracy: 0.7409 - val_loss: 0.5890 - val_accuracy: 0.7090\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.7471 - val_loss: 0.5458 - val_accuracy: 0.7399\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7338 - val_loss: 0.6253 - val_accuracy: 0.6997\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5140 - accuracy: 0.7425 - val_loss: 0.6007 - val_accuracy: 0.7183\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5070 - accuracy: 0.7527 - val_loss: 0.5974 - val_accuracy: 0.6966\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4922 - accuracy: 0.7466 - val_loss: 0.5506 - val_accuracy: 0.7368\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4944 - accuracy: 0.7517 - val_loss: 0.5776 - val_accuracy: 0.7214\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5131 - accuracy: 0.7257 - val_loss: 0.5695 - val_accuracy: 0.7183\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4937 - accuracy: 0.7476 - val_loss: 0.6206 - val_accuracy: 0.6873\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7353 - val_loss: 0.5615 - val_accuracy: 0.7430\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4978 - accuracy: 0.7338 - val_loss: 0.6195 - val_accuracy: 0.6904\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4898 - accuracy: 0.7603 - val_loss: 0.5907 - val_accuracy: 0.7059\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4981 - accuracy: 0.7460 - val_loss: 0.6032 - val_accuracy: 0.7090\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4929 - accuracy: 0.7506 - val_loss: 0.5728 - val_accuracy: 0.7337\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4898 - accuracy: 0.7532 - val_loss: 0.5714 - val_accuracy: 0.7121\n"
     ]
    }
   ],
   "source": [
    "history = model6.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "45377837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6021 - accuracy: 0.7152\n",
      "Test Accuracy: 71.52%\n"
     ]
    }
   ],
   "source": [
    "#y_valid = tf.keras.utils.to_categorical(y_val)\n",
    "test_loss, test_acc = model6.evaluate(X_val, y_val)\n",
    "print('Test Accuracy: {:.2f}%'.format(test_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "60f63d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "721c0d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#joblib.dump(model_RF, \"./random_forest.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f70927",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
